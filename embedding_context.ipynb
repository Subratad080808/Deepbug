{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9025ab87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def token_create(code):\n",
    "    f = code.replace(\"\\n\", \" \")\n",
    "\n",
    "    data = []\n",
    "    \n",
    "    # iterate through each sentence in the file\n",
    "    for i in sent_tokenize(f):\n",
    "        temp = []\n",
    "\n",
    "        # tokenize the sentence into words\n",
    "        for j in word_tokenize(i):\n",
    "            temp.append(j.lower())\n",
    "\n",
    "        data.append(temp)\n",
    "        \n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b001d922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/Testing\\1\\00\\wikihouse\\view.py\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import astor\n",
    "import pandas as pd\n",
    "import os\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import warnings\n",
    "dat=[] \n",
    "warnings.filterwarnings(action = 'ignore')\n",
    "  \n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "path = 'D:/Testing'\n",
    "\n",
    "for root, directories, files in os.walk(path, topdown=False):\n",
    "    for name in files:\n",
    "        print(os.path.join(root, name))\n",
    "        file_path =  (os.path.join(root, name))\n",
    "        \n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            code=f.read()\n",
    "            #print(code)\n",
    "    a= token_create(code)\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ff3d59a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['return',\n",
       " 'self.render',\n",
       " '(',\n",
       " \"'activity.tmpl\",\n",
       " \"'\",\n",
       " ',',\n",
       " 'items=images',\n",
       " '[',\n",
       " ':300',\n",
       " ']',\n",
       " ')',\n",
       " 'class',\n",
       " 'notfound',\n",
       " '(',\n",
       " 'requesthandler',\n",
       " ')',\n",
       " ':',\n",
       " '``',\n",
       " \"''\",\n",
       " \"''\",\n",
       " '``',\n",
       " \"''\",\n",
       " \"''\",\n",
       " 'def',\n",
       " 'get',\n",
       " '(',\n",
       " 'self',\n",
       " ')',\n",
       " ':',\n",
       " 'raise',\n",
       " 'httpnotfound']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[129]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37d7ec4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['if',\n",
       " 'avatar_url',\n",
       " 'not',\n",
       " 'in',\n",
       " 'avatars.twitter_followers',\n",
       " ':',\n",
       " 'avatars.twitter_followers.append',\n",
       " '(',\n",
       " 'avatar_url',\n",
       " ')',\n",
       " 'except',\n",
       " 'urlfetch.downloaderror',\n",
       " ':',\n",
       " 'pass',\n",
       " '#',\n",
       " 'get',\n",
       " 'the',\n",
       " 'disqus',\n",
       " 'avatar',\n",
       " 'permalinks',\n",
       " '.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[125]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e14f708c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 750)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec(\n",
    "    window=5,\n",
    "    min_count=1,\n",
    "    workers=4,\n",
    ")\n",
    "model.build_vocab(a[125], progress_per=1000)\n",
    "model.train(a[125], total_examples=model.corpus_count, epochs=model.epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d0b9bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6438f4c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a5f0360",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KeyedVectors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24388/3206117134.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mwv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"word2vec.wordvectors\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mvector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'get'\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# Get numpy vector of a word\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'KeyedVectors' is not defined"
     ]
    }
   ],
   "source": [
    "wv = KeyedVectors.load(\"word2vec.wordvectors\", mmap='r')\n",
    "\n",
    "vector = wv['get']  # Get numpy vector of a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "deabba6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.batch_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c403d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = model.wv\n",
    "word_vectors.save(\"word2vec.wordvectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e561274f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vec(xp):\n",
    "    for x in xp:\n",
    "        normed_vector = model.wv.get_vector(x, norm=True)\n",
    "        print(\"Process name:\"+x)\n",
    "        print(normed_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f954453",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'language' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24388/3180614749.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24388/50929605.py\u001b[0m in \u001b[0;36mget_vec\u001b[1;34m(xp)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mnormed_vector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Process name:\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormed_vector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[1;34m(self, key, norm)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \"\"\"\n\u001b[1;32m--> 438\u001b[1;33m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill_norms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mget_index\u001b[1;34m(self, key, default)\u001b[0m\n\u001b[0;32m    410\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 412\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Key '{key}' not present\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Key 'language' not present\""
     ]
    }
   ],
   "source": [
    "get_vec(a[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bb67be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.get_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9733c2a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
